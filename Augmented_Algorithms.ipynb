{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e27836-bf83-478c-a127-64725757b160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34766172-a1db-45f1-9eb5-66f61bbf10d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read in CSVs for EAF., distance from Riparian Buf, forest age/type\n",
    "path = 'Beyond450_EAF_avg_ExportTable.csv' \n",
    "Beyond450_EAF = pd.read_csv(path)\n",
    "EAF = pd.read_csv(\"Compartment_avgEAF.csv\")\n",
    "dist_from_RB = pd.read_csv(\"Compartment_avgDistance_RB.csv\")\n",
    "conversion_1937_1957 = pd.read_csv(\"conversion_1937_1957.csv\")\n",
    "conversion_1957_1974 = pd.read_csv(\"conversion_1957_1974.csv\")\n",
    "conversion_1974_1996 = pd.read_csv(\"conversion_1974_1996.csv\")\n",
    "evergreen = pd.read_csv(\"evergreen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1304af06-8720-492b-8e7a-e3ce4d2ffc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in CSV for overall inv. supervised data with farmland, riparian features to append former data to\n",
    "invasion = pd.read_csv(\"Compartment_Inva_ExportTable.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee31bf5-de2a-47cd-8904-72c0a6a44a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance_Riparian_Buffer</th>\n",
       "      <th>Distance_Farmland</th>\n",
       "      <th>HID</th>\n",
       "      <th>overall_in</th>\n",
       "      <th>individual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136.620988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>25-50%</td>\n",
       "      <td>MIVI-3,LOJA-2,ELUM-1,ROMU-1,LISE-1,CEOR-2,BETH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>75-100%</td>\n",
       "      <td>MIVI-4,CEOR-4,LISE-1,LOJA-1,RUPH-1,ALJU-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137.086561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>50-75%</td>\n",
       "      <td>MIVI-4,CEOR-3,LISE-1,RUPH-1,ELUM-1,LOJA-1,ROMU-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137.086530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>50-75%</td>\n",
       "      <td>MIVI-4,CEOR-3,RUPH-3,LOJA-1,ALJU-1,CIVU-2,LISE-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137.107700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>50-75%</td>\n",
       "      <td>MIVI-3,LISE-2,CEOR-3,RUPH-2,PATO-1,LOJA-2,RUCR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Distance_Riparian_Buffer  Distance_Farmland    HID overall_in  \\\n",
       "0                136.620988                0.0  252.0     25-50%   \n",
       "1                 -1.000000                0.0  253.0    75-100%   \n",
       "2                137.086561                0.0  254.0     50-75%   \n",
       "3                137.086530                0.0  255.0     50-75%   \n",
       "4                137.107700                0.0  256.0     50-75%   \n",
       "\n",
       "                                          individual  \n",
       "0  MIVI-3,LOJA-2,ELUM-1,ROMU-1,LISE-1,CEOR-2,BETH...  \n",
       "1          MIVI-4,CEOR-4,LISE-1,LOJA-1,RUPH-1,ALJU-1  \n",
       "2   MIVI-4,CEOR-3,LISE-1,RUPH-1,ELUM-1,LOJA-1,ROMU-1  \n",
       "3   MIVI-4,CEOR-3,RUPH-3,LOJA-1,ALJU-1,CIVU-2,LISE-2  \n",
       "4  MIVI-3,LISE-2,CEOR-3,RUPH-2,PATO-1,LOJA-2,RUCR...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of unnecessary columns for ML\n",
    "df = invasion.iloc[:,[2,5,10,20,21]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d7d9b1-512f-47d8-875f-2fe430e03a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean data from CSVs, add to df\n",
    "## start with dist_from_RB \n",
    "dist_floodplain = []\n",
    "EAF_list = []\n",
    "for i in range(df.shape[0]): #iterate over range of num rows of df\n",
    "    HID = df.iloc[i,2] #find the compartment ID for current iteration\n",
    "    idx = dist_from_RB.index[dist_from_RB['HID'] == HID] #find which index of dist_from_RB equals current HID iteration\n",
    "    mean_distance = dist_from_RB.at[idx[0], 'MEAN_Distance_From_RB'] #retrieves value from mean d col at row specified by idx\n",
    "    dist_floodplain.append(mean_distance * 3.28) #meters to feet formula\n",
    "\n",
    "for i in range(df.shape[0]): #same proc for EAF\n",
    "    HID = df.iloc[i,2] \n",
    "    idx = EAF.index[EAF['HID'] == HID] #find which index of overall EAF equals current HID iteration\n",
    "    mean_EAF = EAF.at[idx[0], 'MEAN_EAF'] #retrieves value from mean d col at row specified by idx\n",
    "    EAF_list.append(mean_EAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd19f02-e6e0-4541-9e84-7e046928b520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance_Riparian_Buffer</th>\n",
       "      <th>Distance_Farmland</th>\n",
       "      <th>HID</th>\n",
       "      <th>overall_in</th>\n",
       "      <th>individual</th>\n",
       "      <th>EAF</th>\n",
       "      <th>Dist_Floodplain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136.620988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>25-50%</td>\n",
       "      <td>MIVI-3,LOJA-2,ELUM-1,ROMU-1,LISE-1,CEOR-2,BETH...</td>\n",
       "      <td>38.745098</td>\n",
       "      <td>814.578296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>75-100%</td>\n",
       "      <td>MIVI-4,CEOR-4,LISE-1,LOJA-1,RUPH-1,ALJU-1</td>\n",
       "      <td>58.200000</td>\n",
       "      <td>1281.677749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137.086561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>50-75%</td>\n",
       "      <td>MIVI-4,CEOR-3,LISE-1,RUPH-1,ELUM-1,LOJA-1,ROMU-1</td>\n",
       "      <td>42.064516</td>\n",
       "      <td>898.304107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137.086530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>50-75%</td>\n",
       "      <td>MIVI-4,CEOR-3,RUPH-3,LOJA-1,ALJU-1,CIVU-2,LISE-2</td>\n",
       "      <td>36.842105</td>\n",
       "      <td>646.795242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137.107700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>50-75%</td>\n",
       "      <td>MIVI-3,LISE-2,CEOR-3,RUPH-2,PATO-1,LOJA-2,RUCR...</td>\n",
       "      <td>35.789474</td>\n",
       "      <td>578.104646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Distance_Riparian_Buffer  Distance_Farmland    HID overall_in  \\\n",
       "0                136.620988                0.0  252.0     25-50%   \n",
       "1                300.000000                0.0  253.0    75-100%   \n",
       "2                137.086561                0.0  254.0     50-75%   \n",
       "3                137.086530                0.0  255.0     50-75%   \n",
       "4                137.107700                0.0  256.0     50-75%   \n",
       "\n",
       "                                          individual        EAF  \\\n",
       "0  MIVI-3,LOJA-2,ELUM-1,ROMU-1,LISE-1,CEOR-2,BETH...  38.745098   \n",
       "1          MIVI-4,CEOR-4,LISE-1,LOJA-1,RUPH-1,ALJU-1  58.200000   \n",
       "2   MIVI-4,CEOR-3,LISE-1,RUPH-1,ELUM-1,LOJA-1,ROMU-1  42.064516   \n",
       "3   MIVI-4,CEOR-3,RUPH-3,LOJA-1,ALJU-1,CIVU-2,LISE-2  36.842105   \n",
       "4  MIVI-3,LISE-2,CEOR-3,RUPH-2,PATO-1,LOJA-2,RUCR...  35.789474   \n",
       "\n",
       "   Dist_Floodplain  \n",
       "0       814.578296  \n",
       "1      1281.677749  \n",
       "2       898.304107  \n",
       "3       646.795242  \n",
       "4       578.104646  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix dist_floodplain values for PW buffer HIDs\n",
    "for i in range(df.shape[0]):\n",
    "    if(df.iloc[i,2] >= 80 and df.iloc[i,2] <= 246):\n",
    "        dist_floodplain[i] = 300\n",
    "for i in range(df.shape[0]):\n",
    "    if(df.iloc[i,2] <= 79):\n",
    "        dist_floodplain[i] = 0\n",
    "# assign riparian buffer distance to 300 meters if not within 450 ft of pw buffer\n",
    "for i in range(df.shape[0]):\n",
    "    if(df.iloc[i,0] == -1):\n",
    "        df.iloc[i,0] = 300\n",
    "# assign new FP dist and EAF lists to df\n",
    "df = df.assign(EAF = EAF_list)\n",
    "df = df.assign(Dist_Floodplain = dist_floodplain)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4457d666-dde9-4f30-a3e3-b0592c1a096d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add in converted forest\n",
    "con_37 = [] ## create empty list for each forest conversion\n",
    "con_57 = []\n",
    "con_74 = []\n",
    "for i in range(df.shape[0]):\n",
    "    HID = df.iloc[i,2]\n",
    "    if(any(HID == conversion_1937_1957['HID'])): #if the current HID exists in converted forest df\n",
    "        idx = conversion_1937_1957['HID'] ==  HID\n",
    "        con_37.append(float(conversion_1937_1957[idx]['PERCENTAGE'])) #extract series from idx in conv forest df then convert to percentage float\n",
    "    else:\n",
    "        con_37.append(0) #if tabulate overlay did not overlap with any conv forest, overlay is 0 percent\n",
    "    if(any(HID == conversion_1957_1974['HID'])): #same procedure for other conv forest dfs\n",
    "        idx = conversion_1957_1974['HID'] ==  HID\n",
    "        con_57.append(float(conversion_1957_1974[idx]['PERCENTAGE'])) \n",
    "    else:\n",
    "        con_57.append(0)\n",
    "    if(any(HID == conversion_1974_1996['HID'])): #same procedure for other conv forest dfs\n",
    "        idx = conversion_1974_1996['HID'] ==  HID\n",
    "        con_74.append(float(conversion_1974_1996[idx]['PERCENTAGE'])) \n",
    "    else:\n",
    "        con_74.append(0)\n",
    "df = df.assign(conversion_1937_1957=con_37) #assign new column to list with percentages\n",
    "df = df.assign(conversion_1957_1974=con_57)\n",
    "df = df.assign(conversion_1974_1996=con_74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135316eb-83c0-49ad-bd21-b1ad00acf68c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#evergreen forest\n",
    "eg = []\n",
    "for i in range(df.shape[0]):\n",
    "    HID = df.iloc[i,2]\n",
    "    if(any(HID == evergreen['HID'])): #if the current HID exists in converted forest df\n",
    "        idx = evergreen['HID'] ==  HID\n",
    "        eg.append(float(evergreen[idx]['PERCENTAGE'])) #extract series from idx in conv forest df then convert to percentage float\n",
    "    else:\n",
    "        eg.append(0)\n",
    "df = df.assign(evergreen_forest = eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b671766a-5e62-4492-991f-536132762210",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage ranges to numeric, cover class values\n",
    "percentage = {'5-25%': 2, '25-50%': 3, '50-75%': 4, '75-100%': 5}\n",
    "numeric_values = []\n",
    "\n",
    "for p in df['overall_in']:\n",
    "    #convert the percentage range to a numeric value\n",
    "    numeric_value = percentage.get(p)\n",
    "    numeric_values.append(numeric_value)\n",
    "    \n",
    "# add new column with numeric values\n",
    "df['overall_numeric'] = numeric_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c96458-36cb-48ea-b2cf-db27a6795efc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d30bfea0-890e-432f-8b53-a1a56e9010b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from intro_Data_4_3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69c7c70b-9a2f-4070-a1d1-17a7138f2ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428571428571429\n",
      "Test accuracy = 0.64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Predicted  2  3  4  5\n",
       " Actual               \n",
       " 2          2  0  0  0\n",
       " 3          2  5  1  0\n",
       " 4          0  0  2  2,\n",
       " 0.6428571428571429)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Reg\n",
    "idx = df[\"Distance_Riparian_Buffer\"] == 300\n",
    "tempdf = df[idx] #get rid of entries skewed by riparian buf (20 total)\n",
    "idx = tempdf[\"Dist_Floodplain\"] > 1200 \n",
    "tempdf = tempdf.drop(tempdf[idx].index) #get rid of outlier far from floodplain \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = np.array(tempdf.drop(columns=['individual', 'overall_in','overall_numeric', 'HID']))\n",
    "y = np.array(tempdf['overall_numeric'])\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = tts(X,y,test_size=0.4, random_state = 146) #test size of 0.2 yielded better results, but K-fold with k=5 did not\n",
    "\n",
    "ss = SS()\n",
    "Xtrain = ss.fit_transform(Xtrain)\n",
    "Xtest = ss.transform(Xtest)\n",
    "# PC = PCA(n_components = 2)\n",
    "# Xtrain = PC.fit_transform(Xtrain)\n",
    "# Xtest = PC.transform(Xtest)\n",
    "\n",
    "log = LR()\n",
    "log.fit(Xtrain,ytrain)\n",
    "y_pred = log.predict(Xtest)\n",
    "print(log.score(Xtest, ytest))\n",
    "\n",
    "matrix = compare_classes(y_pred, ytest)\n",
    "matrix\n",
    "\n",
    "#wildly inconsistent, but scaling + PCs make it more accurate (occasionally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4de9efca-ec80-47a5-bcae-6bc7dca0ee5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy 0.5\n",
      "Test accuracy = 0.50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Predicted  2  3  4  5\n",
       " Actual               \n",
       " 2          0  1  0  0\n",
       " 3          1  6  2  0\n",
       " 4          0  1  1  2,\n",
       " 0.5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RFC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "X = np.array(tempdf.drop(columns=['individual', 'overall_in','overall_numeric', 'HID']))\n",
    "y = np.array(tempdf['overall_numeric'])\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = tts(X,y,test_size=0.4) #test size of 0.2 yielded better results, but K-fold with k=5 did not\n",
    "\n",
    "# do not scale for ensemble\n",
    "\n",
    "# PC = PCA()\n",
    "# Xtrain = PC.fit_transform(Xtrain)\n",
    "# Xtest = PC.transform(Xtest)\n",
    "\n",
    "#random forests can handle high dimensionality\n",
    "\n",
    "rfc = RFC(random_state = 14) #reducing n_estimators from 100 to 50 increased accuracy\n",
    "rfc.fit(Xtrain,ytrain)\n",
    "y_pred = rfc.predict(Xtest)\n",
    "print(\"Random Forest Accuracy\", rfc.score(Xtest, ytest))\n",
    "\n",
    "matrix = compare_classes(y_pred, ytest)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f87ef97-91d1-4fcb-9bcc-3863262da949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Accuracy: 0.34782608695652173\n",
      "Test accuracy = 0.35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Predicted  2  3  4  5\n",
       " Actual               \n",
       " 2          0  2  0  0\n",
       " 3          3  7  4  0\n",
       " 4          0  3  1  1\n",
       " 5          0  0  2  0,\n",
       " 0.34782608695652173)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neural Network (full dataset)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Assuming you have already loaded your data into 'tempdf'\n",
    "\n",
    "X = np.array(df.drop(columns=['individual', 'overall_in', 'overall_numeric', 'HID']))\n",
    "y = np.array(df['overall_numeric'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.4)\n",
    "\n",
    "ss = SS()\n",
    "Xtrain = ss.fit_transform(Xtrain)\n",
    "Xtest = ss.transform(Xtest)\n",
    "# PC = PCA(n_components = 3)\n",
    "# Xtrain = PC.fit_transform(Xtrain)\n",
    "# Xtest = PC.transform(Xtest)\n",
    "\n",
    "# Create and train the MLPClassifier\n",
    "mlp = MLPClassifier(random_state=42, max_iter = 400)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = mlp.score(X_test, y_test)\n",
    "print(\"MLP Classifier Accuracy:\", accuracy)\n",
    "\n",
    "# You can also use your compare_classes function to display the confusion matrix\n",
    "matrix = compare_classes(y_pred, y_test)\n",
    "matrix\n",
    "#LESS ACCURATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "80ef09f1-1fab-4482-9d72-d49478c4f847",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Accuracy: 0.5714285714285714\n",
      "Test accuracy = 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Predicted  2  3  4  5\n",
       " Actual               \n",
       " 2          1  2  0  0\n",
       " 3          2  4  0  0\n",
       " 4          0  1  2  0\n",
       " 5          0  0  1  1,\n",
       " 0.5714285714285714)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neural Network (no outliers)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = np.array(tempdf.drop(columns=['individual', 'overall_in', 'overall_numeric', 'HID']))\n",
    "y = np.array(tempdf['overall_numeric'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.4)\n",
    "\n",
    "ss = SS()\n",
    "Xtrain = ss.fit_transform(Xtrain)\n",
    "Xtest = ss.transform(Xtest)\n",
    "# PC = PCA(n_components = 3)\n",
    "# Xtrain = PC.fit_transform(Xtrain)\n",
    "# Xtest = PC.transform(Xtest)\n",
    "\n",
    "# Create and train the MLPClassifier\n",
    "mlp = MLPClassifier(random_state=14, max_iter = 300)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = mlp.score(X_test, y_test)\n",
    "print(\"MLP Classifier Accuracy:\", accuracy)\n",
    "\n",
    "# You can also use your compare_classes function to display the confusion matrix\n",
    "matrix = compare_classes(y_pred, y_test)\n",
    "matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46361a31-3d33-4b15-a9d1-30319e188a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77b2c576-ce03-4db6-9427-6471ee2c795b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#RFC determine best hyperparams\n",
    "##min_samples_split\n",
    "min_samples_range = np.arange(2, 11)\n",
    "max_depth_range = np.arange(2, 11)\n",
    "columns = ['min_samples_range', 'max_depth_range', 'accuracy']\n",
    "scores = pd.DataFrame(columns = columns)\n",
    "for s in min_samples_range:\n",
    "    for m in max_depth_range:\n",
    "        rfc = RFC(min_samples_split = s, max_depth = m)\n",
    "        train_scores,test_scores = do_Kfold(rfc,X,y,5)\n",
    "        new_row = {'min_samples_range': s,'max_depth_range': m, 'accuracy': np.mean(np.array(test_scores))}\n",
    "        scores = pd.concat([scores, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "276d9770-0f02-4ac4-96c0-807bd48a261a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42010582010582004"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max value for scores generated above\n",
    "# min_samples_split commonly delivers best accuracy at 2\n",
    "\n",
    "# min_samples_range           3\n",
    "# max_depth_range             2\n",
    "# accuracy             0.484848\n",
    "# Name: 9, dtype: object\n",
    "\n",
    "# min_samples_range           3\n",
    "# max_depth_range             5\n",
    "# accuracy             0.514286\n",
    "\n",
    "# min_samples_range           3\n",
    "# max_depth_range             9\n",
    "# accuracy             0.514286\n",
    "scores.loc[scores['accuracy'].idxmax(),:]\n",
    "# np.mean(np.array(scores['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f965e380-7952-4e49-84d6-47a9631e5333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MLP classifier determine best hyperparams\n",
    "# Define the ranges for hyperparameters\n",
    "hidden_layer_sizes_range = [(10,), (20,), (30,)]\n",
    "activation_range = ['relu', 'logistic']\n",
    "alpha_range = [0.0001, 0.001, 0.01]\n",
    "columns = ['hidden_layer_sizes', 'activation', 'alpha', 'accuracy']\n",
    "scores = pd.DataFrame(columns=columns)\n",
    "\n",
    "for hidden_layer_sizes in hidden_layer_sizes_range:\n",
    "    for activation in activation_range:\n",
    "        for alpha in alpha_range:\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, alpha=alpha, max_iter = 10000)\n",
    "            train_scores, test_scores = do_Kfold(mlp, X, y, 5)\n",
    "            new_row = {\n",
    "                'hidden_layer_sizes': hidden_layer_sizes,\n",
    "                'activation': activation,\n",
    "                'alpha': alpha,\n",
    "                'accuracy': np.mean(np.array(test_scores))\n",
    "            }\n",
    "            scores = pd.concat([scores, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n",
    "\n",
    "# Now 'scores' DataFrame contains accuracy scores for different hyperparameter combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ab24f4b-170f-4a53-b22a-5c7cbdb46a79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hidden_layer_sizes          20\n",
       "activation            logistic\n",
       "alpha                     0.01\n",
       "accuracy                   0.6\n",
       "Name: 11, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max value for scores generated above\n",
    "# min_samples_split commonly delivers best accuracy at 2\n",
    "\n",
    "scores.loc[scores['accuracy'].idxmax(),:]\n",
    "#10\n",
    "#relu\n",
    "#0.01\n",
    "#0.6\n",
    "\n",
    "#20\n",
    "#logistic\n",
    "#0.0001\n",
    "#0.62\n",
    "\n",
    "# hidden_layer_sizes          10\n",
    "# activation            logistic\n",
    "# alpha                   0.0001\n",
    "# accuracy              0.628571\n",
    "\n",
    "# hidden_layer_sizes          10\n",
    "# activation            logistic\n",
    "# alpha                   0.0001\n",
    "# accuracy              0.485714\n",
    "# Name: 3, dtype: object\n",
    "\n",
    "# hidden_layer_sizes          10\n",
    "# activation            logistic\n",
    "# alpha                    0.001\n",
    "# accuracy                   0.6\n",
    "\n",
    "# np.mean(np.array(scores['accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647fae0b-d81c-4142-a7cc-4dd8703d934e",
   "metadata": {},
   "source": [
    "# Algorithm consistently shows max accuracy with\n",
    "    hidden_layer_sizes          10-20\n",
    "    activation - logistic\n",
    "    alpha: 0.0001-0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cd57bb-6ed5-46c1-b31f-43cbd867858e",
   "metadata": {},
   "source": [
    "## Fine-tune further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b8aeba5a-1888-4b48-aa46-5d334029ba8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#MLP classifier determine best hyperparams pt. 2\n",
    "\n",
    "# Define the ranges for hyperparameters\n",
    "hidden_layer_sizes_range = np.arange(10,16) #use arange to create list from 10 to 20\n",
    "activation_range = 'logistic'\n",
    "alpha_range = np.arange(1,6) * 0.0001\n",
    "columns = ['hidden_layer_sizes', 'alpha', 'accuracy']\n",
    "scores = pd.DataFrame(columns=columns)\n",
    "\n",
    "for hidden_layer_sizes in hidden_layer_sizes_range:\n",
    "    for alpha in alpha_range:\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation='logistic', alpha=alpha, max_iter = 10000)\n",
    "        train_scores, test_scores = do_Kfold(mlp, X, y, 5)\n",
    "        new_row = {\n",
    "            'hidden_layer_sizes': hidden_layer_sizes,\n",
    "            'alpha': alpha,\n",
    "            'accuracy': np.mean(np.array(test_scores))\n",
    "        }\n",
    "        scores = pd.concat([scores, pd.DataFrame(new_row, index=[0])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "23a4f5a3-8704-4628-9104-65656dd5da7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hidden_layer_sizes          15\n",
       "alpha                   0.0005\n",
       "accuracy              0.685714\n",
       "Name: 29, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.loc[scores['accuracy'].idxmax(),:]\n",
    "\n",
    "# hidden_layer_sizes        10\n",
    "# alpha                 0.0004\n",
    "# accuracy                 0.6\n",
    "# Name: 3, dtype: object\n",
    "\n",
    "# hidden_layer_sizes          10\n",
    "# alpha                   0.0003\n",
    "# accuracy              0.628571\n",
    "\n",
    "# hidden_layer_sizes          13\n",
    "# alpha                   0.0004\n",
    "# accuracy              0.628571\n",
    "\n",
    "# hidden_layer_sizes          15\n",
    "# alpha                   0.0003\n",
    "# accuracy              0.685714\n",
    "\n",
    "# hidden_layer_sizes          11\n",
    "# alpha                   0.0005\n",
    "# accuracy              0.628571\n",
    "\n",
    "# hidden_layer_sizes          15\n",
    "# alpha                   0.0005\n",
    "# accuracy              0.685714\n",
    "#np.mean(np.array(scores['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b76c71b2-6fc3-4675-be50-091f9c974026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier Accuracy: 0.7142857142857143\n",
      "Test accuracy = 0.71\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Predicted  2  3  4  5\n",
       " Actual               \n",
       " 2          2  0  0  0\n",
       " 3          2  5  1  0\n",
       " 4          0  0  2  1\n",
       " 5          0  0  0  1,\n",
       " 0.7142857142857143)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try MLP with new params KFold\n",
    "\n",
    "X = np.array(tempdf.drop(columns=['individual', 'overall_in', 'overall_numeric', 'HID']))\n",
    "y = np.array(tempdf['overall_numeric'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.4, random_state = 146)\n",
    "\n",
    "# ss = SS()\n",
    "# Xtrain = ss.fit_transform(Xtrain)\n",
    "# Xtest = ss.transform(Xtest)\n",
    "# PC = PCA(n_components = 3)\n",
    "# Xtrain = PC.fit_transform(Xtrain)\n",
    "# Xtest = PC.transform(Xtest)\n",
    "\n",
    "# Create and train the MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=10, activation='logistic', alpha=0.0004, max_iter = 10000, random_state= 146)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = mlp.score(X_test, y_test)\n",
    "print(\"MLP Classifier Accuracy:\", accuracy)\n",
    "\n",
    "# You can also use your compare_classes function to display the confusion matrix\n",
    "matrix = compare_classes(y_pred, y_test)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "01111984-be13-4019-b86d-b47fe211253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.42857142857142855, 0.42857142857142855, 0.42857142857142855, 0.5714285714285714, 0.42857142857142855]\n",
      "Mean Accuracy: 0.45714285714285713\n",
      "Standard Deviation of Test Accuracy: 0.05714285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create the random forest classifier\n",
    "rfc = RFC(random_state=146, n_estimators=100, max_depth = 8, min_samples_split = 5)\n",
    "\n",
    "#convert to numpy array for Kfold function\n",
    "X_arr = np.array(X)\n",
    "y_arr = np.array(y)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "train_scores,test_scores = do_Kfold(rfc,X_arr,y_arr,5, random_state = 146)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", test_scores)\n",
    "\n",
    "# Calculate and print the mean and standard deviation of the scores\n",
    "print(\"Mean Accuracy:\", np.mean(np.array(test_scores)))\n",
    "print(\"Standard Deviation of Test Accuracy:\", np.array(test_scores).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1112951a-e1fb-4afc-bbb0-49038cd22d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance_Riparian_Buffer</th>\n",
       "      <th>Distance_Farmland</th>\n",
       "      <th>HID</th>\n",
       "      <th>overall_in</th>\n",
       "      <th>individual</th>\n",
       "      <th>EAF</th>\n",
       "      <th>Dist_Floodplain</th>\n",
       "      <th>conversion_1937_1957</th>\n",
       "      <th>conversion_1957_1974</th>\n",
       "      <th>conversion_1974_1996</th>\n",
       "      <th>evergreen_forest</th>\n",
       "      <th>overall_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>258.0</td>\n",
       "      <td>25-50%</td>\n",
       "      <td>MIVI-2,LISE-1,ROMU-1,CAAC-2,LOJA-2,CEOR-3</td>\n",
       "      <td>32.571429</td>\n",
       "      <td>818.178278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.999877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300.0</td>\n",
       "      <td>173.037653</td>\n",
       "      <td>264.0</td>\n",
       "      <td>25-50%</td>\n",
       "      <td>RUPH-2,MIVI-3,LOJA-1,PATO-2,CEOR-1,ROMU-1,LISE-1</td>\n",
       "      <td>64.142857</td>\n",
       "      <td>675.009333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>300.0</td>\n",
       "      <td>361.244783</td>\n",
       "      <td>265.0</td>\n",
       "      <td>5-25%</td>\n",
       "      <td>CEOR-2,MIVI-2,LISE-1,RUPH-1</td>\n",
       "      <td>45.309091</td>\n",
       "      <td>698.781851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300.0</td>\n",
       "      <td>522.854292</td>\n",
       "      <td>266.0</td>\n",
       "      <td>5-25%</td>\n",
       "      <td>CEOR-2,MIVI-2,LISE-1,RUPH-1</td>\n",
       "      <td>43.714286</td>\n",
       "      <td>580.959644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.782920</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>300.0</td>\n",
       "      <td>331.102949</td>\n",
       "      <td>267.0</td>\n",
       "      <td>5-25%</td>\n",
       "      <td>RUPH-1,CEOR-2,LOJA-1</td>\n",
       "      <td>61.739130</td>\n",
       "      <td>538.781197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.577919</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Distance_Riparian_Buffer  Distance_Farmland    HID overall_in  \\\n",
       "6                      300.0           0.000000  258.0     25-50%   \n",
       "8                      300.0         173.037653  264.0     25-50%   \n",
       "9                      300.0         361.244783  265.0      5-25%   \n",
       "10                     300.0         522.854292  266.0      5-25%   \n",
       "11                     300.0         331.102949  267.0      5-25%   \n",
       "\n",
       "                                          individual        EAF  \\\n",
       "6          MIVI-2,LISE-1,ROMU-1,CAAC-2,LOJA-2,CEOR-3  32.571429   \n",
       "8   RUPH-2,MIVI-3,LOJA-1,PATO-2,CEOR-1,ROMU-1,LISE-1  64.142857   \n",
       "9                        CEOR-2,MIVI-2,LISE-1,RUPH-1  45.309091   \n",
       "10                       CEOR-2,MIVI-2,LISE-1,RUPH-1  43.714286   \n",
       "11                              RUPH-1,CEOR-2,LOJA-1  61.739130   \n",
       "\n",
       "    Dist_Floodplain  conversion_1937_1957  conversion_1957_1974  \\\n",
       "6        818.178278                   0.0                   0.0   \n",
       "8        675.009333                   0.0                   0.0   \n",
       "9        698.781851                   0.0                   0.0   \n",
       "10       580.959644                   0.0                   0.0   \n",
       "11       538.781197                   0.0                   0.0   \n",
       "\n",
       "    conversion_1974_1996  evergreen_forest  overall_numeric  \n",
       "6              99.999877          0.000000                3  \n",
       "8               0.000000          0.000000                3  \n",
       "9               0.000000          0.000000                2  \n",
       "10              0.000000          4.782920                2  \n",
       "11              0.000000         78.577919                2  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1dc595-9800-4a3b-a55f-138e2d58ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
